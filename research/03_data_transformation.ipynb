{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Cell_Segmentation_YOLO-v8/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Cell_Segmentation_YOLO-v8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    train_path: Path\n",
    "    validation_path: Path\n",
    "    test_path: Path\n",
    "    YAML_path: Path\n",
    "    val_size: float\n",
    "    aug_size: int\n",
    "    aug_params: dict\n",
    "    dataset_val_status: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cellseg.constant import *\n",
    "from src.cellseg.utils.main_utils import create_directories, read_yaml\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_file_path = CONFIG_FILE_PATH,\n",
    "        params_file_path = PARAMS_FILE_PATH,\n",
    "        schema_file_path = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        self.schema = read_yaml(schema_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        params = self.params.augmentation\n",
    "        \n",
    "        dataset_val_status_file = self.config.data_validation.STATUS_FILE\n",
    "        \n",
    "        with open(dataset_val_status_file, 'r') as f:\n",
    "            status = f.read()\n",
    "        \n",
    "        status = bool(str.split(status)[-1])\n",
    "        \n",
    "        create_directories([config.root_dir, config.train_path, config.validation_path])\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            train_path=config.train_path,\n",
    "            validation_path=config.validation_path,\n",
    "            test_path=config.test_path,\n",
    "            YAML_path=config.YAML_path,\n",
    "            val_size=config.val_size,\n",
    "            aug_size=config.aug_size,\n",
    "            aug_params=params,\n",
    "            dataset_val_status=status\n",
    "        )\n",
    "        \n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cellseg import logger\n",
    "from src.cellseg.utils.main_utils import dir_sample_creation\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import random\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def transform_preparation(self, crop_dim):\n",
    "        transform = A.Compose([\n",
    "            A.Crop(\n",
    "                x_min=self.config.aug_params.Crop.x_min,\n",
    "                y_min=self.config.aug_params.Crop.y_min,\n",
    "                x_max=crop_dim,\n",
    "                y_max=crop_dim,\n",
    "                p=self.config.aug_params.Crop.p\n",
    "            ),\n",
    "            A.Resize(\n",
    "                height=self.config.aug_params.Resize.height,\n",
    "                width=self.config.aug_params.Resize.width,\n",
    "                p=self.config.aug_params.Resize.p\n",
    "            ),\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=self.config.aug_params.RandomBrightnessContrast.brightness_limit,\n",
    "                contrast_limit=self.config.aug_params.RandomBrightnessContrast.contrast_limit,\n",
    "                p=self.config.aug_params.RandomBrightnessContrast.p\n",
    "            ),\n",
    "            A.RandomGamma(\n",
    "                gamma_limit=self.config.aug_params.RandomGamma.gamma_limit,\n",
    "                p=self.config.aug_params.RandomGamma.p\n",
    "            ),\n",
    "            A.Rotate(\n",
    "                limit=self.config.aug_params.Rotate.limit,\n",
    "                border_mode=self.config.aug_params.Rotate.border_mode,\n",
    "                p=self.config.aug_params.Rotate.p\n",
    "            ),\n",
    "            A.HorizontalFlip(\n",
    "                p=self.config.aug_params.HorizontalFlip.p\n",
    "            ),\n",
    "            A.VerticalFlip(\n",
    "                p=self.config.aug_params.VerticalFlip.p\n",
    "            ),\n",
    "            A.RandomResizedCrop(\n",
    "                scale=(0.5,1.0),\n",
    "                size=(self.config.aug_params.Resize.height, self.config.aug_params.Resize.width)\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        return transform\n",
    "    \n",
    "    def balance_augment_data_lists(self):\n",
    "        color_list = []\n",
    "        grayscale_list = []\n",
    "        \n",
    "        for folder in tqdm(os.listdir(self.config.data_path)):\n",
    "            img = cv2.imread(os.path.join(\n",
    "                self.config.data_path,\n",
    "                folder,\n",
    "                'images',\n",
    "                folder + '.png'\n",
    "            ))\n",
    "            \n",
    "            if np.array_equal(img[:,:,0], img[:,:,1]) and np.array_equal(img[:,:,1], img[:,:,2]):\n",
    "                grayscale_list.append(folder + '.png')\n",
    "            else:\n",
    "                color_list.append(folder + '.png')\n",
    "        \n",
    "        if len(grayscale_list) >= len(color_list):\n",
    "            gray_aug_count = self.config.aug_size * len(grayscale_list) - len(grayscale_list)\n",
    "            color_aug_count = self.config.aug_size * len(grayscale_list) - len(color_list)\n",
    "        else:\n",
    "            gray_aug_count = self.config.aug_size * len(color_list) - len(grayscale_list)\n",
    "            color_aug_count = self.config.aug_size * len(color_list) - len(color_list)\n",
    "            \n",
    "        grayscale_list.extend(random.choices(grayscale_list, k=gray_aug_count))\n",
    "        color_list.extend(random.choices(color_list, k=color_aug_count))\n",
    "        \n",
    "        return grayscale_list, color_list\n",
    "    \n",
    "    def chunk_transform(self, chunk_list):\n",
    "        for img_name in tqdm(chunk_list):\n",
    "            img_path = os.path.join(\n",
    "                self.config.data_path,\n",
    "                str.split(img_name, '.')[0],\n",
    "                'images',\n",
    "                img_name\n",
    "            )\n",
    "            \n",
    "            image = cv2.cvtColor(cv2.imread(img_path, 1), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            crop_dim = min(image.shape[0], image.shape[1])\n",
    "            transform = self.transform_preparation(crop_dim)\n",
    "            \n",
    "            masks = []\n",
    "            mask_dir = os.path.join(self.config.data_path, str.split(img_name, '.')[0], 'masks')\n",
    "            \n",
    "            for mask_name in os.listdir(mask_dir):\n",
    "                mask_img = cv2.imread(os.path.join(mask_dir, mask_name), 0)\n",
    "                masks.append(mask_img)\n",
    "            \n",
    "            composite_mask = np.stack(masks, axis=-1)\n",
    "            \n",
    "            augmentations = transform(image=image, mask=composite_mask)\n",
    "            \n",
    "            dir_sample_creation(augmentations, str.split(img_name, '.')[0], self.config.train_path)\n",
    "\n",
    "    def data_to_YOLO_formating(self):\n",
    "        logger.info(\"YOLO formating started!\")\n",
    "            \n",
    "        for dir in tqdm(os.listdir(self.config.train_path)):\n",
    "            shutil.move(\n",
    "                os.path.join(\n",
    "                    self.config.train_path,\n",
    "                    dir,\n",
    "                    'images',\n",
    "                    dir + '.png',\n",
    "                ),\n",
    "                self.config.train_path\n",
    "            )\n",
    "            \n",
    "            masks = ''\n",
    "            \n",
    "            for cell_mask in os.listdir(os.path.join(self.config.train_path, dir, 'masks')):\n",
    "                \n",
    "                cell_mask_str = '0'\n",
    "\n",
    "                cell_mask_img = cv2.imread(os.path.join(\n",
    "                    self.config.train_path,\n",
    "                    dir,\n",
    "                    'masks',\n",
    "                    cell_mask\n",
    "                ), 0)\n",
    "\n",
    "                contours, _ = cv2.findContours(\n",
    "                    cell_mask_img,\n",
    "                    cv2.RETR_LIST,\n",
    "                    cv2.CHAIN_APPROX_NONE\n",
    "                )\n",
    "                \n",
    "                if contours:\n",
    "                    for dot in contours[0]:\n",
    "                        cell_mask_str += ' ' + str(dot[0][0] / cell_mask_img.shape[1]) + ' ' + str(dot[0][1] / cell_mask_img.shape[0])\n",
    "\n",
    "                    masks += cell_mask_str + '\\n'\n",
    "\n",
    "            with open(os.path.join(self.config.train_path, dir + '.txt'), 'w') as file:\n",
    "                file.write(masks)\n",
    "            \n",
    "            shutil.rmtree(os.path.join(self.config.train_path, dir))\n",
    "                \n",
    "        logger.info(\"YOLO formating finished!\")\n",
    "\n",
    "    def train_validation_separation(self):\n",
    "        logger.info(\"Train/validation split started!\")\n",
    "        \n",
    "        img_list = os.listdir(self.config.train_path)\n",
    "        img_list = [s for s in img_list if '.png' in s]\n",
    "        \n",
    "        _, val_list = train_test_split(\n",
    "            img_list,\n",
    "            test_size=self.config.val_size,\n",
    "            random_state=42,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        for img in val_list:\n",
    "            img_path = os.path.join(self.config.train_path, img)\n",
    "            ann_path = os.path.join(self.config.train_path, str.split(img, '.')[0] + '.txt')\n",
    "            \n",
    "            shutil.move(img_path, self.config.validation_path, )\n",
    "            shutil.move(ann_path, self.config.validation_path)\n",
    "        \n",
    "        logger.info(\"Train/validation split finished!\")\n",
    "    \n",
    "    def dataset_yaml_creation(self):\n",
    "        yaml_content = {\n",
    "            'train': os.path.join(os.getcwd(), self.config.train_path),\n",
    "            'val': os.path.join(os.getcwd(), self.config.validation_path),\n",
    "            'test': '',\n",
    "            'nc': 1,\n",
    "            'names': ['Cell']\n",
    "        }\n",
    "        \n",
    "        yaml_file = yaml.safe_dump(yaml_content, default_flow_style=None, sort_keys=False)\n",
    "        \n",
    "        with open(self.config.YAML_path, 'w') as file:\n",
    "            file.write(yaml_file)\n",
    "        logger.info(\"File dataset.yaml created!\")\n",
    "\n",
    "    def transformation_compose(self):\n",
    "        if self.config.dataset_val_status:\n",
    "            if not os.listdir(self.config.train_path) and not os.listdir(self.config.validation_path):\n",
    "                logger.info(\"Data augmentation started!\")\n",
    "                grayscale_list, color_list = self.balance_augment_data_lists()\n",
    "                self.chunk_transform(color_list)\n",
    "                self.chunk_transform(grayscale_list)\n",
    "                logger.info(\"Data augmentation finished!\")\n",
    "                self.data_to_YOLO_formating()\n",
    "                self.train_validation_separation()\n",
    "                self.dataset_yaml_creation()\n",
    "            elif not os.path.exists(self.config.YAML_path):\n",
    "                logger.info(\"Transformation already performed!\")\n",
    "                self.dataset_yaml_creation()\n",
    "            else:\n",
    "                logger.info(\"Transformation already performed!\")\n",
    "        else:\n",
    "            logger.info(\"Transformation stoped, dataset isn't valid!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-21 13:53:00,088: INFO: main_utils: created directory at: artifacts]\n",
      "[2024-11-21 13:53:00,090: INFO: main_utils: created directory at: artifacts/data_transformation]\n",
      "[2024-11-21 13:53:00,090: INFO: main_utils: created directory at: artifacts/data_transformation/train]\n",
      "[2024-11-21 13:53:00,091: INFO: main_utils: created directory at: artifacts/data_transformation/validation]\n",
      "[2024-11-21 13:53:00,093: INFO: 3174540254: Data augmentation started!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 670/670 [00:02<00:00, 251.83it/s]\n",
      "100%|██████████| 1686/1686 [02:00<00:00, 13.94it/s]\n",
      "100%|██████████| 1686/1686 [05:47<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-21 14:00:51,640: INFO: 3174540254: Data augmentation finished!]\n",
      "[2024-11-21 14:00:51,640: INFO: 3174540254: YOLO formating started!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3372/3372 [02:09<00:00, 26.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-21 14:03:00,787: INFO: 3174540254: YOLO formating finished!]\n",
      "[2024-11-21 14:03:00,790: INFO: 3174540254: Train/validation split started!]\n",
      "[2024-11-21 14:03:00,865: INFO: 3174540254: Train/validation split finished!]\n",
      "[2024-11-21 14:03:00,868: INFO: 3174540254: File dataset.yaml created!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.transformation_compose()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e                                                                                                                                                                                                                                                                                                                                                                         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
