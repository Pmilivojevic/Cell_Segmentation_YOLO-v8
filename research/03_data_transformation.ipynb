{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Cell_Segmentation_YOLO-v8/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Cell_Segmentation_YOLO-v8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    train_path: Path\n",
    "    validation_path: Path\n",
    "    val_size: float\n",
    "    apply_aug: bool\n",
    "    aug_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cellseg.constant import *\n",
    "from src.cellseg.utils.main_utils import create_directories, read_yaml\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_file_path = CONFIG_FILE_PATH,\n",
    "        params_file_path = PARAMS_FILE_PATH,\n",
    "        schema_file_path = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        self.schema = read_yaml(schema_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        \n",
    "        create_directories([config.root_dir, config.train_path, config.validation_path])\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            train_path=config.train_path,\n",
    "            validation_path=config.validation_path,\n",
    "            val_size=config.val_size,\n",
    "            apply_aug=config.apply_aug,\n",
    "            aug_size=config.aug_size\n",
    "        )\n",
    "        \n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cellseg import logger\n",
    "import shutil\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def data_augmentation(self):\n",
    "        logger.info(\"Data augmentation started!\")\n",
    "        for dir in tqdm(os.listdir(self.config.data_path)):\n",
    "            img_path = os.path.join(\n",
    "                self.config.data_path,\n",
    "                dir,\n",
    "                'images',\n",
    "                dir + '.png'\n",
    "            )\n",
    "            image = cv2.cvtColor(cv2.imread(img_path, 1), cv2.COLOR_BGR2RGB)\n",
    "            crop_dim = min(image.shape[0], image.shape[1])\n",
    "            \n",
    "            transform = A.Compose([\n",
    "                A.Crop(x_min=0, y_min=0, x_max=crop_dim, y_max=crop_dim, always_apply=True),\n",
    "                A.Resize(height=256, width=256, always_apply=True),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.18, contrast_limit=0.18, p=0.5),\n",
    "                A.RandomGamma(gamma_limit=(95, 105), p=0.5),\n",
    "                A.Rotate(limit=120, p=0.7, border_mode=cv2.BORDER_REFLECT),\n",
    "                A.HorizontalFlip(p=0.8),\n",
    "                A.VerticalFlip(p=0.8)\n",
    "            ])\n",
    "            \n",
    "            masks_list = []\n",
    "            for cell_mask in os.listdir(os.path.join(self.config.data_path, dir, 'masks')):\n",
    "                cell_mask_img = cv2.imread(os.path.join(\n",
    "                    self.config.data_path,\n",
    "                    dir,\n",
    "                    'masks',\n",
    "                    cell_mask\n",
    "                ), 0)\n",
    "                \n",
    "                masks_list.append(cell_mask_img)\n",
    "            \n",
    "            for i in range(self.config.aug_size):\n",
    "                augmentations = transform(image=image, masks=masks_list)\n",
    "                \n",
    "                dir_image_path = os.path.join(\n",
    "                    self.config.data_path,\n",
    "                    dir + '_' + str(i),\n",
    "                    'images',\n",
    "                )\n",
    "                os.makedirs(dir_image_path, exist_ok=True)\n",
    "                cv2.imwrite(\n",
    "                    os.path.join(dir_image_path, dir + '_' + str(i) + '.png'),\n",
    "                    augmentations['image']\n",
    "                )\n",
    "                \n",
    "                dir_mask_path = os.path.join(\n",
    "                    self.config.data_path,\n",
    "                    dir + '_' + str(i),\n",
    "                    'masks',\n",
    "                )\n",
    "                os.makedirs(dir_mask_path, exist_ok=True)\n",
    "                for i, mask in enumerate(augmentations['masks']):\n",
    "                    cv2.imwrite(\n",
    "                        os.path.join(dir_mask_path, dir + '_mask_' + str(i) + '.png'),\n",
    "                        mask\n",
    "                    )\n",
    "            \n",
    "            # shutil.rmtree(os.path.join(self.config.data_path, dir))\n",
    "        logger.info(\"Data augmentation finished!\")\n",
    "\n",
    "    def data_to_YOLO_formating(self):\n",
    "        logger.info(\"YOLO formating started!\")\n",
    "        if self.config.apply_aug:\n",
    "            marker = '_'\n",
    "        else:\n",
    "            marker = ''\n",
    "            \n",
    "        for dir in tqdm(os.listdir(self.config.data_path)):\n",
    "            if marker in dir:\n",
    "                img_path = os.path.join(\n",
    "                    self.config.data_path,\n",
    "                    dir,\n",
    "                    'images',\n",
    "                    dir + '.png'\n",
    "                )\n",
    "\n",
    "                if self.config.apply_aug:\n",
    "                    shutil.move(img_path, self.config.train_path)\n",
    "                else:\n",
    "                    shutil.copy2(img_path, self.config.train_path)\n",
    "\n",
    "                masks = ''\n",
    "                \n",
    "                for cell_mask in os.listdir(os.path.join(self.config.data_path, dir, 'masks')):\n",
    "                    \n",
    "                    cell_mask_str = '0'\n",
    "\n",
    "                    cell_mask_img = cv2.imread(os.path.join(\n",
    "                        self.config.data_path,\n",
    "                        dir,\n",
    "                        'masks',\n",
    "                        cell_mask\n",
    "                    ), 0)\n",
    "\n",
    "                    contours, _ = cv2.findContours(\n",
    "                        cell_mask_img,\n",
    "                        cv2.RETR_LIST,\n",
    "                        cv2.CHAIN_APPROX_SIMPLE\n",
    "                    )\n",
    "                    \n",
    "                    if contours:\n",
    "                        for dot in contours[0]:\n",
    "                            cell_mask_str += ' ' + str(dot[0][1] / 255) + ' ' + str(dot[0][0] / 255)\n",
    "\n",
    "                        masks += cell_mask_str + '\\n'\n",
    "\n",
    "                with open(os.path.join(self.config.train_path, dir + '.txt'), 'w') as file:\n",
    "                    file.write(masks)\n",
    "\n",
    "                if self.config.apply_aug:\n",
    "                    shutil.rmtree(os.path.join(self.config.data_path, dir))\n",
    "        logger.info(\"YOLO formating finished!\")\n",
    "\n",
    "    def train_validation_separation(self):\n",
    "        logger.info(\"Train/validation split started!\")\n",
    "        \n",
    "        img_list = os.listdir(self.config.train_path)\n",
    "        img_list = [s for s in img_list if '.png' in s]\n",
    "        \n",
    "        _, val_list = train_test_split(\n",
    "            img_list,\n",
    "            test_size=self.config.val_size,\n",
    "            random_state=42,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        for img in val_list:\n",
    "            img_path = os.path.join(self.config.train_path, img)\n",
    "            ann_path = os.path.join(self.config.train_path, str.split(img, '.')[0] + '.txt')\n",
    "            \n",
    "            shutil.move(img_path, self.config.validation_path, )\n",
    "            shutil.move(ann_path, self.config.validation_path)\n",
    "        \n",
    "        logger.info(\"Train/validation split finished!\")\n",
    "    \n",
    "    def dataset_yaml_creation(self):\n",
    "        yaml_content = {\n",
    "            'train': self.config.train_path,\n",
    "            'val': self.config.validation_path,\n",
    "            'test': 'artifacts/data_ingestion/test',\n",
    "            'nc': 1,\n",
    "            'names': ['Cell']\n",
    "        }\n",
    "        \n",
    "        yaml_file = yaml.safe_dump(yaml_content, default_flow_style=None, sort_keys=False)\n",
    "        \n",
    "        with open(os.path.join(self.config.root_dir, 'dataset.yaml'), 'w') as file:\n",
    "            file.write(yaml_file)\n",
    "        logger.info(\"File dataset.yaml created!\")\n",
    "\n",
    "    def sequence_transformation(self):\n",
    "        if self.config.apply_aug:\n",
    "            self.data_augmentation()\n",
    "            self.data_to_YOLO_formating()\n",
    "            self.train_validation_separation()\n",
    "            self.dataset_yaml_creation()\n",
    "        else:\n",
    "            self.data_to_YOLO_formating()\n",
    "            self.train_validation_separation()\n",
    "            self.dataset_yaml_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-12 22:35:07,494: INFO: main_utils: created directory at: artifacts]\n",
      "[2024-10-12 22:35:07,495: INFO: main_utils: created directory at: artifacts/data_transformation]\n",
      "[2024-10-12 22:35:07,496: INFO: main_utils: created directory at: artifacts/data_transformation/train]\n",
      "[2024-10-12 22:35:07,498: INFO: main_utils: created directory at: artifacts/data_transformation/validation]\n",
      "[2024-10-12 22:35:07,499: INFO: 4139087493: Data augmentation started!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 670/670 [01:48<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-12 22:36:56,126: INFO: 4139087493: Data augmentation finished!]\n",
      "[2024-10-12 22:36:56,128: INFO: 4139087493: YOLO formating started!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4020/4020 [01:27<00:00, 45.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-12 22:38:24,026: INFO: 4139087493: YOLO formating finished!]\n",
      "[2024-10-12 22:38:24,027: INFO: 4139087493: Train/validation split started!]\n",
      "[2024-10-12 22:38:24,092: INFO: 4139087493: Train/validation split finished!]\n",
      "[2024-10-12 22:38:24,094: INFO: 4139087493: File dataset.yaml created!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.sequence_transformation()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
