{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Cell_Segmentation_YOLO-v8/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cb03386d-9344-47b1-82f9-868fbb64b4ae/python_projects/Cell_Segmentation_YOLO-v8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    train_path: Path\n",
    "    validation_path: Path\n",
    "    test_path: Path\n",
    "    YAML_path: Path\n",
    "    val_size: float\n",
    "    apply_aug: bool\n",
    "    aug_size: int\n",
    "    aug_params: dict\n",
    "    dataset_val_status: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cellseg.constant import *\n",
    "from src.cellseg.utils.main_utils import create_directories, read_yaml\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_file_path = CONFIG_FILE_PATH,\n",
    "        params_file_path = PARAMS_FILE_PATH,\n",
    "        schema_file_path = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        self.schema = read_yaml(schema_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        params = self.params.augmentation\n",
    "        \n",
    "        dataset_val_status_file = self.config.data_validation.STATUS_FILE\n",
    "        \n",
    "        with open(dataset_val_status_file, 'r') as f:\n",
    "            status = f.read()\n",
    "        \n",
    "        status = bool(str.split(status)[-1])\n",
    "        \n",
    "        create_directories([config.root_dir, config.train_path, config.validation_path])\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            train_path=config.train_path,\n",
    "            validation_path=config.validation_path,\n",
    "            test_path=config.test_path,\n",
    "            YAML_path=config.YAML_path,\n",
    "            val_size=config.val_size,\n",
    "            apply_aug=config.apply_aug,\n",
    "            aug_size=config.aug_size,\n",
    "            aug_params=params,\n",
    "            dataset_val_status=status\n",
    "        )\n",
    "        \n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cellseg import logger\n",
    "import shutil\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def transform_preparation(self, crop_dim):\n",
    "        transform = A.Compose([\n",
    "            A.Crop(\n",
    "                x_min=self.config.aug_params.Crop.x_min,\n",
    "                y_min=self.config.aug_params.Crop.y_min,\n",
    "                x_max=crop_dim,\n",
    "                y_max=crop_dim,\n",
    "                p=self.config.aug_params.Crop.p\n",
    "            ),\n",
    "            A.Resize(\n",
    "                height=self.config.aug_params.Resize.height,\n",
    "                width=self.config.aug_params.Resize.width,\n",
    "                p=self.config.aug_params.Resize.p\n",
    "            ),\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=self.config.aug_params.RandomBrightnessContrast.brightness_limit,\n",
    "                contrast_limit=self.config.aug_params.RandomBrightnessContrast.contrast_limit,\n",
    "                p=self.config.aug_params.RandomBrightnessContrast.p\n",
    "            ),\n",
    "            A.RandomGamma(\n",
    "                gamma_limit=self.config.aug_params.RandomGamma.gamma_limit,\n",
    "                p=self.config.aug_params.RandomGamma.p\n",
    "            ),\n",
    "            A.Rotate(\n",
    "                limit=self.config.aug_params.Rotate.limit,\n",
    "                border_mode=self.config.aug_params.Rotate.border_mode,\n",
    "                p=self.config.aug_params.Rotate.p\n",
    "            ),\n",
    "            A.HorizontalFlip(\n",
    "                p=self.config.aug_params.HorizontalFlip.p\n",
    "            ),\n",
    "            A.VerticalFlip(\n",
    "                p=self.config.aug_params.VerticalFlip.p\n",
    "            ),\n",
    "            A.RandomResizedCrop(\n",
    "                scale=(0.5,1.0),\n",
    "                size=(self.config.aug_params.Resize.height, self.config.aug_params.Resize.width)\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        return transform\n",
    "\n",
    "    def data_augmentation(self):\n",
    "        logger.info(\"Data augmentation started!\")\n",
    "        for dir in tqdm(os.listdir(self.config.data_path)):\n",
    "            img_path = os.path.join(\n",
    "                self.config.data_path,\n",
    "                dir,\n",
    "                'images',\n",
    "                dir + '.png'\n",
    "            )\n",
    "            image = cv2.cvtColor(cv2.imread(img_path, 1), cv2.COLOR_BGR2RGB)\n",
    "            crop_dim = min(image.shape[0], image.shape[1])\n",
    "            \n",
    "            transform = self.transform_preparation(crop_dim)\n",
    "            \n",
    "            masks_list = []\n",
    "            for cell_mask in os.listdir(os.path.join(self.config.data_path, dir, 'masks')):\n",
    "                cell_mask_img = cv2.imread(os.path.join(\n",
    "                    self.config.data_path,\n",
    "                    dir,\n",
    "                    'masks',\n",
    "                    cell_mask\n",
    "                ), 0)\n",
    "                \n",
    "                masks_list.append(cell_mask_img)\n",
    "            \n",
    "            for i in range(self.config.aug_size):\n",
    "                augmentations = transform(image=image, masks=masks_list)\n",
    "                \n",
    "                dir_image_path = os.path.join(\n",
    "                    self.config.data_path,\n",
    "                    dir + '_' + str(i),\n",
    "                    'images',\n",
    "                )\n",
    "                os.makedirs(dir_image_path, exist_ok=True)\n",
    "                cv2.imwrite(\n",
    "                    os.path.join(dir_image_path, dir + '_' + str(i) + '.png'),\n",
    "                    augmentations['image']\n",
    "                )\n",
    "                \n",
    "                dir_mask_path = os.path.join(\n",
    "                    self.config.data_path,\n",
    "                    dir + '_' + str(i),\n",
    "                    'masks',\n",
    "                )\n",
    "                os.makedirs(dir_mask_path, exist_ok=True)\n",
    "                for i, mask in enumerate(augmentations['masks']):\n",
    "                    cv2.imwrite(\n",
    "                        os.path.join(dir_mask_path, dir + '_mask_' + str(i) + '.png'),\n",
    "                        mask\n",
    "                    )\n",
    "            \n",
    "        logger.info(\"Data augmentation finished!\")\n",
    "\n",
    "    def data_to_YOLO_formating(self):\n",
    "        logger.info(\"YOLO formating started!\")\n",
    "        if self.config.apply_aug:\n",
    "            marker = '_'\n",
    "        else:\n",
    "            marker = ''\n",
    "            \n",
    "        for dir in tqdm(os.listdir(self.config.data_path)):\n",
    "            if marker in dir:\n",
    "                img_path = os.path.join(\n",
    "                    self.config.data_path,\n",
    "                    dir,\n",
    "                    'images',\n",
    "                    dir + '.png'\n",
    "                )\n",
    "\n",
    "                if self.config.apply_aug:\n",
    "                    shutil.move(img_path, self.config.train_path)\n",
    "                else:\n",
    "                    shutil.copy2(img_path, self.config.train_path)\n",
    "\n",
    "                masks = ''\n",
    "                \n",
    "                for cell_mask in os.listdir(os.path.join(self.config.data_path, dir, 'masks')):\n",
    "                    \n",
    "                    cell_mask_str = '0'\n",
    "\n",
    "                    cell_mask_img = cv2.imread(os.path.join(\n",
    "                        self.config.data_path,\n",
    "                        dir,\n",
    "                        'masks',\n",
    "                        cell_mask\n",
    "                    ), 0)\n",
    "\n",
    "                    contours, _ = cv2.findContours(\n",
    "                        cell_mask_img,\n",
    "                        cv2.RETR_LIST,\n",
    "                        cv2.CHAIN_APPROX_SIMPLE\n",
    "                    )\n",
    "                    \n",
    "                    if contours:\n",
    "                        for dot in contours[0]:\n",
    "                            cell_mask_str += ' ' + str(dot[0][1] / 255) + ' ' + str(dot[0][0] / 255)\n",
    "\n",
    "                        masks += cell_mask_str + '\\n'\n",
    "\n",
    "                with open(os.path.join(self.config.train_path, dir + '.txt'), 'w') as file:\n",
    "                    file.write(masks)\n",
    "\n",
    "                if self.config.apply_aug:\n",
    "                    shutil.rmtree(os.path.join(self.config.data_path, dir))\n",
    "        logger.info(\"YOLO formating finished!\")\n",
    "\n",
    "    def train_validation_separation(self):\n",
    "        logger.info(\"Train/validation split started!\")\n",
    "        \n",
    "        img_list = os.listdir(self.config.train_path)\n",
    "        img_list = [s for s in img_list if '.png' in s]\n",
    "        \n",
    "        _, val_list = train_test_split(\n",
    "            img_list,\n",
    "            test_size=self.config.val_size,\n",
    "            random_state=42,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        for img in val_list:\n",
    "            img_path = os.path.join(self.config.train_path, img)\n",
    "            ann_path = os.path.join(self.config.train_path, str.split(img, '.')[0] + '.txt')\n",
    "            \n",
    "            shutil.move(img_path, self.config.validation_path, )\n",
    "            shutil.move(ann_path, self.config.validation_path)\n",
    "        \n",
    "        logger.info(\"Train/validation split finished!\")\n",
    "    \n",
    "    def dataset_yaml_creation(self):\n",
    "        yaml_content = {\n",
    "            'train': os.path.join(os.getcwd(), self.config.train_path),\n",
    "            'val': os.path.join(os.getcwd(), self.config.validation_path),\n",
    "            'test': '',\n",
    "            'nc': 1,\n",
    "            'names': ['Cell']\n",
    "        }\n",
    "        \n",
    "        yaml_file = yaml.safe_dump(yaml_content, default_flow_style=None, sort_keys=False)\n",
    "        \n",
    "        with open(self.config.YAML_path, 'w') as file:\n",
    "            file.write(yaml_file)\n",
    "        logger.info(\"File dataset.yaml created!\")\n",
    "\n",
    "    def transformation_compose(self):\n",
    "        if self.config.dataset_val_status:\n",
    "            if not os.listdir(self.config.train_path) and not os.listdir(self.config.validation_path):\n",
    "                if self.config.apply_aug:\n",
    "                    self.data_augmentation()\n",
    "                    self.data_to_YOLO_formating()\n",
    "                    self.train_validation_separation()\n",
    "                else:\n",
    "                    self.data_to_YOLO_formating()\n",
    "                    self.train_validation_separation()\n",
    "                \n",
    "                self.dataset_yaml_creation()\n",
    "                \n",
    "            elif not os.path.exists(self.config.YAML_path):\n",
    "                logger.info(\"Transformation already performed!\")\n",
    "                self.dataset_yaml_creation()\n",
    "            else:\n",
    "                logger.info(\"Transformation already performed!\")\n",
    "        else:\n",
    "            logger.info(\"Transformation stoped, dataset isn't valid!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-13 20:48:58,613: INFO: main_utils: created directory at: artifacts]\n",
      "[2024-11-13 20:48:58,617: INFO: main_utils: created directory at: artifacts/data_transformation]\n",
      "[2024-11-13 20:48:58,618: INFO: main_utils: created directory at: artifacts/data_transformation/train]\n",
      "[2024-11-13 20:48:58,619: INFO: main_utils: created directory at: artifacts/data_transformation/validation]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-13 20:48:58,623: INFO: 3269231514: Transformation already performed!]\n",
      "[2024-11-13 20:48:58,626: INFO: 3269231514: File dataset.yaml created!]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.transformation_compose()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e                                                                                                                                                                                                                                                                                                                                                                         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
